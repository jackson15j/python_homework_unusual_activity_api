* Unusual Activity API:
Simple to project to expose an endpoint to highlight unusual activity.

** Problem:

creating an endpoint which will receive a payload representing a
user's action. This endpoint should be called =/event= and can expect
the following payload:

#+BEGIN_EXAMPLE json
  {
    "type": "deposit",
    "amount": "42.00",
    "user_id": 1,
    "t": 10
  }
#+END_EXAMPLE

- =type= is either =deposit= or =withdraw=.
- =user_id= represents a unique user.
- =t= denotes the second we receive the payload, this will always be
  increasing and unique.

The endpoint should respond as follows:

#+BEGIN_EXAMPLE json
  {
    "alert": true,
    "alert_codes": [
      30,
      123
    ],
    "user_id": 1
  }
#+END_EXAMPLE

Given the following set of rules;

- If the user meets these criteria, add the code to the =alert_codes=.
- If =alert_codes= is empty, =alert= should be =false=, otherwise
  =true=.
- =alert_codes= can be provided in any order.
- Always provide the =user_id= in the response payload.

Expected Codes:

- Code: =1100=: A withdraw amount over 100.
- Code: =30=: 3 consecutive withdraws.
- Code: =300=: 3 consecutive increasing deposits (ignoring withdraws).
- Code: =123=: Accumulative deposit amount over a window of 30 seconds
  is over 200.

** Usage:

- Curl Example:

  #+BEGIN_EXAMPLE shell
    curl -XPOST http://127.0.0.1:5000/event -H 'Content-Type: application/json' \
         -d '{"type": "deposit", "amount": "42.00", "user_id": 1, "t": 0}'
  #+END_EXAMPLE

** Pre-Thoughts:

- Business logic separated from endpoint framework:
  - Unittest business logic.
  - Validate each requirement in isolation.
  - Maintain state (DB (/potentially/ sqlite for ease).
- Code Flow:
  - Parse Request.
  - /Potentially:/ early validation. eg. unique =t= values.
  - Store request history by =user_id=.
  - Get all data by =user_id=.
  - Run each check.
  - Collate =alert_codes=, if any.
  - Generate Response.
- Contract Boundary testing of the endpoint:
  - Pro's:
    - Real World: Contract's enforce hard-boundaries, upfront
      design/collaboration, parallelisation of implementation,
      code/test generation, VCS-based tooling.
    - Test Generation by: [[https://specmatic.in/documentation.html][Specmatic]], [[https://dredd.org/en/latest/index.html][Dredd]] is a time-saver vs bespoke
      integration test writing.
      - Personally like Specmatic for it's test generation that can be
        supplemented with OpenAPI spec =examples= and/or [[https://cucumber.io/docs/gherkin/][Gherkin]]
        tests.
      - [[https://docs.pact.io/consumer][PACT]] consumer-driven testing would require writing bespoke
        tests + a broker. Overkill for this single Server exercise,
        but a fine test if you had bespoke API endpoint tests and
        wanted to pull in the PACT library as a trial of the PACT
        Broker.
  - Con's:
    - Test Generation is a greater productivity boost when you use
      code generation of Server/Client endpoints + Models.
      - Sadly, python code generation is still poor, where the output
        requires heavy templating and post-generation cleanup to allow
        seamless regeneration (Compare: Golang's [[https://github.com/deepmap/oapi-codegen/][Github:
        deepmap/oapi-codegen/]] vs Golang/Python/etc's [[https://github.com/swagger-api/swagger-codegen][Github:
        swagger-api/swagger-codegen]] output).
        - Easy to fall into the trap of:
          - Generate once, move spec to be generated from Producer's
            code/docstrings, Producer implementation is now a gate for
            Consumers/tooling/generative-testing to start.
          - Duplication from Code and Spec being kept in sync.
      - Spec writing + docker/CI setup for Specmatic is non-trivial
        and probably too much work for a quick homework project.
  - Not a fan of mocking API routing to avoid running up the Server
    for testing. Seen (and had to educate) too many Teams that have
    over-mocked the routing (ie. Self-contained tests that validate
    the mock state and not Production code).
- Release:
  - *MVP:* Steps to run `python <server.py>`.
  - *Next:* Python package to be installed into a venv, and then run.
  - *Ideal:* Docker container with running app as entrypoint.
  - *Ideal:* Github CI actions (lint, build, test, etc).


** Proposed Data Structures:

*** Account History + User Accounts:

#+NAME: AccountHistory_JSON
#+BEGIN_EXAMPLE json
  {
    <t>: {user_id: <int>, type: <deposit/withdrawl>, amount: <float>},
  }
#+END_EXAMPLE

#+NAME: UserAccounts_JSON
#+BEGIN_EXAMPLE json
  {
    <user_id>: {last_t: <t>, total: <float>},
  }
#+END_EXAMPLE

- Pro's:
  - =t in AccountHistory= check for =t= uniqueness.
  - =t > list(AccountHistory.keys())[-1]= for increasing check.
  - Separate =UserAccounts= for quick lookups + deposit/withdrawl
    changes.
  - Tracking of =last_t= for quick checking for missed transactions.
- Con's:
  - Messy to look up by =User_id= in =AccountHistory= for historical
    checks.

*** Nested User Accounts:

#+BEGIN_EXAMPLE json
  {
    <user_id>: {
      last_t: <t>,
      total: <float>,
      history/audit: [{t: <int>, type: <deposit/withdrawl>, amount: <float>}, ]
    },
  }
#+END_EXAMPLE

Plus separate global ~last_t = <int>~ in Request Handler.

- Pro's:
  - =t > last_t= for increasing check.
  - =user_id= as a key for initial uniqueness checks.
  - Quickly apply deposit/withdrawl changes.
  - Tracking of =last_t= for quick checking for missed transactions.
  - Historical checks are easier to do than [[*Account History + User Accounts:][Account History + User
    Accounts]], because of the tight data coupling.
- Con's:
  - Assumption that =t= is unique if it passes the =t > last_t= global
    check.
  - global =last_t= shortcomings:
    - Would need a singleton to handle concurrent requests.
    - Would need to dump to DB to handle reboots.
    - Use DB/library/ServiceMesh/Service to centralise logic in a
      horizontally scaled situation.
  - The audit history should be split into a separate data structure
    to handle it's continuous growth, vs the rest of the user account
    fields.

*** SQL Tables:

#+BEGIN_EXAMPLE sql
  CREATE TABLE AuditHistory (
         T int NOT NULL UNIQUE,
         UserId int NOT NULL,
         Type varchar(20),
         Amount float,
         CONSTRAINT CHK_Type CHECK (Type='deposit' OR Type='withdrawl'),
         PRIMARY KEY (T),
         FOREIGN KEY (UserId) REFERENCES UserAccount(UserId)
  );
#+END_EXAMPLE

#+BEGIN_EXAMPLE sql
  CREATE TABLE UserAccount (
         UserId int NOT NULL UNIQUE,
         Total float,
         PRIMARY KEY (UserId)
  );
#+END_EXAMPLE

- Pro's:
  - Constraints at the DB level centralises logic:
    - Simplified Application logic due to reacting to DB Errors only.
    - Validation maintained when transitioning Application language.
    - Centralised logic is ideal for shared DB's.
    - Validation is still in place for any direct DB modifications.
  - =SELECT T FROM AuditHistory WHERE T < :t ORDER BY
    insertion_timestamp DESC LIMIT 1;= for increasing check.
    - Can use the SQL engines get last row equivalent, as an optimisation.
    - With a bit more thinking this could be an SQL constraint that
      checks the last value.
      - Did a little digging and this can be done with a =BEFORE
        INSERT= Trigger, to create a custom constraint.
  - =SELECT * FROM AuditHistory WHERE UserId == :user_id ORDER BY T=
    to get data for uniqueness checks.
- Con's:
  - Need to Duplicate validation up the stack if you want to reduce
    latency / DB-hits.
    - Same argument as FrontEnd Validation vs Reacting to Backend
      Validation.
  - Opaque behaviour from Application code point of view - requires
    good documentation and/or SQL literacy.
